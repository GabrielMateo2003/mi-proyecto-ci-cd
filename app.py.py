# -*- coding: utf-8 -*-
"""IA_94_affairs2026_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nVovixm64qiU9B2qofp5xIgX38NFpHVM
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn import linear_model
from sklearn import model_selection
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import r2_score
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

url =  'https://raw.githubusercontent.com/Darwin2016/dataset2022/main/dataSETS/affairs.csv'

df = pd.read_csv(url, delimiter=',')
df.head()

df.shape

df['affair'].value_counts()

X = df.drop("affair", axis=1)
y = df.affair
X.head()

from sklearn.feature_selection import SelectKBest

best=SelectKBest(k=4)
X_new = best.fit_transform(X, y)
X_new.shape
selected = best.get_support(indices=True)
print(X.columns[selected])

X_new

import matplotlib.pyplot as plt
from matplotlib import colors
import seaborn as sb

used_features =X.columns[selected]

colormap = plt.cm.viridis
plt.figure(figsize=(8,8))
plt.title('Pearson Correlation of Features', y=1.05, size=15)
sb.heatmap(df[used_features].astype(float).corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)

X=df[used_features]

X.head()

from sklearn.preprocessing import StandardScaler
#Seperar el dataframe en datos de train y datos de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)

# Escalar los datos de entrada
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

X_test.shape,X_train.shape

modelo = linear_model.LogisticRegression(C=0.03,solver='liblinear',max_iter=100, random_state=None)

#Entrenamiento del Modelo
modelo.fit(X_train_scaled,y_train)

from sklearn import model_selection
seed = 7
name='Logistic Regression'
kfold = model_selection.KFold(n_splits=10, random_state=seed,shuffle=True)
cv_results = model_selection.cross_val_score(modelo, X_train, y_train, cv=kfold, scoring='accuracy')
msg = "%s: %f (%f)" % (name, cv_results.mean(), cv_results.std())
print(msg)

# Predecimos sobre nuestro set de traint
y_pred = modelo.predict(X_test_scaled)
print(y_pred)

"""Generamos las metricas de evaluación

"Accuracy" es la precisión { Si recordamos, la exactitud (o «accuracy«) representa el porcentaje de predicciones correctas frente al total.}

"Precision" es la exactitud {La precisión, (o“precision”) se refiere a lo cerca que está el resultado de una predicción del valor verdadero. }

"Recall" es la sensibilidad {La sensibilidad (o recall) representa la tasa de verdaderos positivos (True Positive Rate) ó TP.}
"""

print("Accuracy: ",accuracy_score(y_test,y_pred))
print("Recall: ",recall_score(y_test,prediccion))
print("Precision: ",precision_score(y_test,prediccion))
print("F1: ",f1_score(y_test,prediccion))
print("R2: ",r2_score(y_test,prediccion))

#generamos la matriz de confusión

cnf_matrix=confusion_matrix(y_test, prediccion)
cnf_matrix

print(classification_report(y_test, prediccion))

# import required modules
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

class_names=[0,1] # name  of classes
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)
# create heatmap
sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion Matrix', y=1.1)
plt.ylabel('Actual Label')
plt.xlabel('Predicted Label')

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix,classification_report

sns.set()

cm = confusion_matrix(y_test, y_pred, labels=[0,1])
f, (ax1) = plt.subplots(figsize=(3,3),nrows=1)

# crear mapa de calor dibujar mapa de calor: cmap="Reds"
sns.heatmap(pd.DataFrame(cm),linewidths = 0.05, annot=True, cmap="Blues",fmt='g')
ax1.set_title('Matriz de Confusión') #título
ax1.set_xlabel('Predicción') #eje x
ax1.set_ylabel('Real') #eje y
f.savefig('RF-1.jpg')

"""##Usando Arboles de Decisión"""

from sklearn.tree import DecisionTreeClassifier

#Crear el modelo de Arbol para Clasificación
modelotree = DecisionTreeClassifier(max_depth = 3)

#Entrenamiento del Modelo
modelotree.fit(X_train_scaled,y_train)

# Predecimos sobre nuestro set de traint
pred_test = modelotree.predict(X_test_scaled)

print('Accuracy sobre conjunto de Test:', accuracy_score(pred_test,y_test))

import matplotlib.pyplot as plt
from sklearn.tree import plot_tree

# Estructura del árbol creado
# ------------------------------------------------------------------------------
fig, ax = plt.subplots(figsize=(15, 5))

print(f"Profundidad del árbol: {modelotree.get_depth()}")
print(f"Número de nodos terminales: {modelotree.get_n_leaves()}")

plot = plot_tree(
            decision_tree = modelotree,
            feature_names = df.drop(columns = "affair").columns,
            class_names   = 'affair',
            filled        = True,
            impurity      = False,
            fontsize      = 8,
            precision     = 2,
            ax            = ax
       )

#generamos la matriz de confusión

cnf_matrix=confusion_matrix(y_test, pred_test)
cnf_matrix

print("Accuracy: ",accuracy_score(y_test,pred_test))
print("Recall: ",recall_score(y_test,pred_test))
print("Precision: ",precision_score(y_test,pred_test))
print("F1: ",f1_score(y_test,pred_test))
print("R2: ",r2_score(y_test,pred_test))

"""#Random Forest"""

#RandomForest
from sklearn.ensemble import RandomForestClassifier

modelRF = RandomForestClassifier(max_depth=3,criterion='entropy',min_samples_split=5, min_samples_leaf=2,n_estimators=20)

modelRF.fit(X_train_scaled,y_train)

y_pred = modelRF.predict(X_test_scaled)

randomForest_score = accuracy_score(y_test, y_pred)

print("Random Forest Score :{}".format(randomForest_score))

#generamos la matriz de confusión

cnf_matrix=confusion_matrix(y_test, y_pred)
cnf_matrix

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix,classification_report

sns.set()

cm = confusion_matrix(y_test, y_pred, labels=[0,1])
f, (ax1) = plt.subplots(figsize=(3,3),nrows=1)

# crear mapa de calor dibujar mapa de calor: cmap="Reds"
sns.heatmap(pd.DataFrame(cm),linewidths = 0.05, annot=True, cmap="Blues",fmt='g')
ax1.set_title('Matriz de Confusión') #título
ax1.set_xlabel('Predicción') #eje x
ax1.set_ylabel('Real') #eje y
f.savefig('RF-1.jpg')

print(classification_report(y_test, y_pred))

print("Accuracy: ",accuracy_score(y_test,y_pred))
print("Recall: ",recall_score(y_test,y_pred))
print("Precision: ",precision_score(y_test,y_pred))
print("F1: ",f1_score(y_test,y_pred))
print("R2: ",r2_score(y_test,y_pred))

"""#SVM"""

#SVM
from sklearn import svm

modelSVM = svm.SVC(kernel='rbf')

modelSVM.fit(X_train_scaled, y_train)

y_pred = modelSVM.predict(X_test_scaled)

svm_score=accuracy_score(y_test, y_pred)

print("SVM's Accuracy:{0}".format(accuracy_score(y_test, y_pred)))

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix,classification_report

sns.set()

cm = confusion_matrix(y_test, y_pred, labels=[0,1])
f, (ax1) = plt.subplots(figsize=(3,3),nrows=1)

# crear mapa de calor dibujar mapa de calor: cmap="Reds"
sns.heatmap(pd.DataFrame(cm),linewidths = 0.05, annot=True, cmap="Blues",fmt='g')
ax1.set_title('Matriz de Confusión') #título
ax1.set_xlabel('Predicción') #eje x
ax1.set_ylabel('Real') #eje y
f.savefig('SVM-1.jpg')

print(classification_report(y_test, y_pred))

print("Accuracy: ",accuracy_score(y_test,y_pred))
print("Recall: ",recall_score(y_test,y_pred))
print("Precision: ",precision_score(y_test,y_pred))
print("F1: ",f1_score(y_test,y_pred))
print("R2: ",r2_score(y_test,y_pred))

"""#Modelos Basados en Boosting"""